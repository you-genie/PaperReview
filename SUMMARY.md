# Table of contents

* [ðŸ’¡ Paper Study](README.md)

## ðŸ¤– Multimodal

* [Multimodal LLM](multimodal/multimodal-llm/README.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] MINIGPT-4: ENHANCING VISION-LANGUAGE UNDERSTANDING WITH ADVANCED LARGE LANGUAGE MODELS](multimodal/multimodal-llm/minigpt-4-enhancing-vision-language-understanding-with-advanced-large-language-models.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] WORLD MODEL ON MILLION-LENGTH VIDEO AND LANGUAGE WITH RINGATTENTION](multimodal/multimodal-llm/world-model-on-million-length-video-and-language-with-ringattention.md)

## ðŸ¥‘ NLP

* [Tools](nlp/tools/README.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs](nlp/tools/api-bank-a-comprehensive-benchmark-for-tool-augmented-llms.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] ToolLLM](nlp/tools/toolllm.md)
* [Agents](nlp/agents/README.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] KwaiAgents](nlp/agents/kwaiagents.md)
* [Long](nlp/long/README.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] LongLoRA: EFFICIENT FINE-TUNING OF LONG- CONTEXT LARGE LANGUAGE MODELS](nlp/long/longlora-efficient-fine-tuning-of-long-context-large-language-models.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] Memorizing Transformers](nlp/long/memorizing-transformers.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] LongLLaMA: Focused Transformer Training for Context Scaling](nlp/long/longllama-focused-transformer-training-for-context-scaling.md)
* [Efficient LLM](nlp/efficient-llm/README.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] Fast Inference of Mixture-of-Experts Language Models with Offloading](nlp/efficient-llm/fast-inference-of-mixture-of-experts-language-models-with-offloading.md)
  * [\[ë…¼ë¬¸ë¦¬ë·°\] GPTQ: ACCURATE POST-TRAINING QUANTIZATION FOR GENERATIVE PRE-TRAINED TRANSFORMERS](nlp/efficient-llm/gptq-accurate-post-training-quantization-for-generative-pre-trained-transformers.md)
* [Benchmark](nlp/benchmark/README.md)
  * [MT-Bench](nlp/benchmark/mt-bench.md)
